{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1717c9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "796da4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars=200)\n",
    "# wiki = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain.tools import Tool\n",
    "\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars=200)\n",
    "\n",
    "\n",
    "def wiki_tool_fn(query: str) -> str:\n",
    "    return api_wrapper.run(query)\n",
    "\n",
    "\n",
    "wiki_tool = Tool(\n",
    "    name=\"wiki\",\n",
    "    func=wiki_tool_fn,\n",
    "    description=\"Use this to get Wikipedia information. Input is a search query string.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0103d098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wiki'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "661bca10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x771251854110>, search_kwargs={})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "# from langchain_openai import OpenAIEmbeddings\n",
    "# from langchain_ollama import OllamaEmbeddings\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(\"https://docs.smith.langchain.com\")\n",
    "docs = loader.load()\n",
    "documents = RecursiveCharacterTextSplitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    ").split_documents(docs)\n",
    "\n",
    "vectorDB = FAISS.from_documents(documents, OllamaEmbeddings(model=\"mxbai-embed-large\"))\n",
    "retriever = vectorDB.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "542cf078",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools.retriever import create_retriever_tool\n",
    "retrieval_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"langsmith_search\",\n",
    "    \"Search for onformation about LangSmith. For any questions about LangSmith, you must use this tool.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3aeb86dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'langsmith_search'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_tool.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f1cb6910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Arxiv Tool\n",
    "# from langchain_community.utilities import ArxivAPIWrapper\n",
    "# from langchain_community.tools import ArxivQueryRun\n",
    "\n",
    "# arxiv_wrapper = ArxivAPIWrapper(top_k_results=1, doc_content_chars=200)\n",
    "# arxiv = ArxivQueryRun(api_wrapper=arxiv_wrapper)\n",
    "# arxiv.name\n",
    "\n",
    "from langchain_community.utilities import ArxivAPIWrapper\n",
    "from langchain.tools import Tool\n",
    "\n",
    "arxiv_wrapper = ArxivAPIWrapper(top_k_results=1, doc_content_chars=200)\n",
    "\n",
    "def arxiv_tool_fn(query: str) -> str:\n",
    "    return arxiv_wrapper.run(query)\n",
    "\n",
    "arxiv_tool = Tool(\n",
    "    name=\"arxiv\",\n",
    "    func=arxiv_tool_fn,\n",
    "    description=\"Search Arxiv for research papers. Input should be a search query string.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3f697731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='wiki', description='Use this to get Wikipedia information. Input is a search query string.', func=<function wiki_tool_fn at 0x771289e6b100>),\n",
       " Tool(name='arxiv', description='Search Arxiv for research papers. Input should be a search query string.', func=<function arxiv_tool_fn at 0x771289e6ae80>),\n",
       " Tool(name='langsmith_search', description='Search for onformation about LangSmith. For any questions about LangSmith, you must use this tool.', args_schema=<class 'langchain_core.tools.retriever.RetrieverInput'>, func=functools.partial(<function _get_relevant_documents at 0x7712880ad4e0>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x771251854110>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'), coroutine=functools.partial(<function _aget_relevant_documents at 0x7712880ad620>, retriever=VectorStoreRetriever(tags=['FAISS', 'OllamaEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x771251854110>, search_kwargs={}), document_prompt=PromptTemplate(input_variables=['page_content'], input_types={}, partial_variables={}, template='{page_content}'), document_separator='\\n\\n', response_format='content'))]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools = [wiki_tool, arxiv_tool, retrieval_tool]\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2ca3cbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### only works with OpenAI\n",
    "# from langchain import hub\n",
    "# # Get the prompt to use - you can modify this!\n",
    "# prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
    "# prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6980892c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"LangSmith is a powerful search engine for scientific literature. It’s designed to help researchers quickly find relevant papers across various disciplines. Here’s a breakdown of what it offers:\\n\\n* **Focus on Scientific Papers:** It specializes in scientific literature, particularly papers from ArXiv, PubMed, and Scopus.  It aims to prioritize papers related to physics, chemistry, biology, and engineering.\\n* **Advanced Search Capabilities:**  LangSmith employs a sophisticated index to understand the connections between papers. It allows you to search for concepts, authors, keywords, and even relationships between papers – going beyond simple keyword matching.\\n* **Multiple Search Modes:**  It supports various search modes including keyword search, concept search, and query-based search.  You can even define ‘queries’ to narrow down results to a specific focus.\\n* **Cross-Document Linking:** LangSmith is designed to provide cross-linking between papers – helping you understand connections between research.\\n* **Searchable Databases:**  It integrates with major databases like ArXiv, PubMed, and Scopus, providing access to a vast collection of publications.\\n* **Customizable Filters:** Offers granular filters like author, year, keyword, and more to tailor your search results.\\n\\n**Resources:**\\n* [LangSmith Website](https://langsmith.com/): This is the official source for the tool.  You'll find detailed documentation and usage examples.\\n* [LangSmith Documentation](https://langsmith.com/docs):\\n\\nWould you like me to help you with a specific task related to LangSmith, such as how to use it for a particular search or understanding its features? Do you want me to provide a sample query?\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"LangSmith is a powerful search engine for scientific literature. It’s designed to help researchers quickly find relevant papers across various disciplines. Here’s a breakdown of what it offers:\\n\\n* **Focus on Scientific Papers:** It specializes in scientific literature, particularly papers from ArXiv, PubMed, and Scopus.  It aims to prioritize papers related to physics, chemistry, biology, and engineering.\\n* **Advanced Search Capabilities:**  LangSmith employs a sophisticated index to understand the connections between papers. It allows you to search for concepts, authors, keywords, and even relationships between papers – going beyond simple keyword matching.\\n* **Multiple Search Modes:**  It supports various search modes including keyword search, concept search, and query-based search.  You can even define ‘queries’ to narrow down results to a specific focus.\\n* **Cross-Document Linking:** LangSmith is designed to provide cross-linking between papers – helping you understand connections between research.\\n* **Searchable Databases:**  It integrates with major databases like ArXiv, PubMed, and Scopus, providing access to a vast collection of publications.\\n* **Customizable Filters:** Offers granular filters like author, year, keyword, and more to tailor your search results.\\n\\n**Resources:**\\n* [LangSmith Website](https://langsmith.com/): This is the official source for the tool.  You'll find detailed documentation and usage examples.\\n* [LangSmith Documentation](https://langsmith.com/docs):\\n\\nWould you like me to help you with a specific task related to LangSmith, such as how to use it for a particular search or understanding its features? Do you want me to provide a sample query?\""
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "llm = ChatOllama(model=\"gemma3:1b\")\n",
    "\n",
    "# Initialize the agent with correct agent type\n",
    "agent = initialize_agent(\n",
    "    tools,\n",
    "    llm,\n",
    "    agent=AgentType.STRUCTURED_CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Run the agent\n",
    "agent.run(\"Tell me about LangSmith\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e935db73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action_input\": \"Machine Learning is a field of artificial intelligence that focuses on enabling computer systems to learn from data without being explicitly programmed. Instead of relying on pre-defined rules, machine learning algorithms analyze data to identify patterns, make predictions, and improve their performance over time. Here’s a breakdown of key aspects:\\n\\n* **Core Idea:** Machine learning algorithms learn from data, much like humans do, by identifying correlations and trends.\\n* **Types of Machine Learning:** There are several types, including:\\n    * **Supervised Learning:** The algorithm learns from labeled data (input and desired output). Examples: classification (predicting categories) and regression (predicting a continuous value).\\n    * **Unsupervised Learning:** The algorithm learns from unlabeled data and discovers hidden patterns.\\n    * **Reinforcement Learning:** The algorithm learns by trial and error, receiving rewards or penalties for its actions.\\n* **Algorithms:** Popular algorithms include: \\n    * **Linear Regression:**  Predicts a continuous value based on a linear relationship with input features.\\n    * **Decision Trees:** Create tree-like structures to make decisions.\\n    * **Support Vector Machines (SVMs):**  Find the best boundary to separate different classes of data.\\n    * **Neural Networks:** Inspired by the human brain, these are complex networks of interconnected nodes that can learn highly sophisticated patterns.\\n* **Applications:** Machine learning is used in nearly every industry, including:\\n    * **Recommendation Systems (Netflix, Amazon):** Suggesting items based on user behavior.\\n    * **Fraud Detection:** Identifying suspicious transactions.\\n    * **Image Recognition:** Identifying objects in images.\\n    * **Natural Language Processing (NLP):** Understanding and generating human language.\\n    * **Self-Driving Cars:** Enabling vehicles to navigate and make decisions.\\n\\n**Key Benefits:** Machine learning automates tasks, improves accuracy, and enables faster insights from data. It’s constantly evolving and impacting many aspects of our lives.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Tell me about Machine Learning',\n",
       " 'output': 'Machine Learning is a field of artificial intelligence that focuses on enabling computer systems to learn from data without being explicitly programmed. Instead of relying on pre-defined rules, machine learning algorithms analyze data to identify patterns, make predictions, and improve their performance over time. Here’s a breakdown of key aspects:\\n\\n* **Core Idea:** Machine learning algorithms learn from data, much like humans do, by identifying correlations and trends.\\n* **Types of Machine Learning:** There are several types, including:\\n    * **Supervised Learning:** The algorithm learns from labeled data (input and desired output). Examples: classification (predicting categories) and regression (predicting a continuous value).\\n    * **Unsupervised Learning:** The algorithm learns from unlabeled data and discovers hidden patterns.\\n    * **Reinforcement Learning:** The algorithm learns by trial and error, receiving rewards or penalties for its actions.\\n* **Algorithms:** Popular algorithms include: \\n    * **Linear Regression:**  Predicts a continuous value based on a linear relationship with input features.\\n    * **Decision Trees:** Create tree-like structures to make decisions.\\n    * **Support Vector Machines (SVMs):**  Find the best boundary to separate different classes of data.\\n    * **Neural Networks:** Inspired by the human brain, these are complex networks of interconnected nodes that can learn highly sophisticated patterns.\\n* **Applications:** Machine learning is used in nearly every industry, including:\\n    * **Recommendation Systems (Netflix, Amazon):** Suggesting items based on user behavior.\\n    * **Fraud Detection:** Identifying suspicious transactions.\\n    * **Image Recognition:** Identifying objects in images.\\n    * **Natural Language Processing (NLP):** Understanding and generating human language.\\n    * **Self-Driving Cars:** Enabling vehicles to navigate and make decisions.\\n\\n**Key Benefits:** Machine learning automates tasks, improves accuracy, and enables faster insights from data. It’s constantly evolving and impacting many aspects of our lives.'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# agent.run(\"Tell me about Machine Learning\")\n",
    "agent.invoke(\"Tell me about Machine Learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e92ed1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "  \"action\": \"arxiv\",\n",
      "  \"action_input\": \"Reinforcement Learning Roadmap for Machine Learning & Deep Learning Enthusiasts\",\n",
      "  \"thought\": \"Given your existing skills, a focused roadmap is best. Here’s a breakdown, emphasizing understanding the core concepts of RL and how they relate to your background:  It's structured around building foundational knowledge, then focusing on key algorithms and frameworks.  We’ll prioritize practical application.\",\n",
      "  \"action\": \"langsmith_search\",\n",
      "  \"query\": \"Reinforcement Learning Roadmap for Machine Learning & Deep Learning Enthusiasts\",\n",
      "  \"thought\": \"I'll use this to locate resources suitable for this audience.  It will be a preliminary guide.  Let's start with a broad overview and then delve deeper into specific areas.\",\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"action\": \"Final Answer\",\n",
      "  \"thought\": \"I'll provide a basic roadmap with resource suggestions. Let’s start with a general outline.\",\n",
      "  \"action\": \"wiki\",\n",
      "  \"action_input\": \"Wikipedia – Reinforcement Learning Roadmap\",\n",
      "  \"thought\": \"Start with a quick overview of the field to gain context.\",\n",
      "  \"action\": \"wiki\",\n",
      "  \"action_input\": \"Search: \\\"Reinforcement Learning Basics\\\"\",\n",
      "  \"thought\": \"Get a general understanding of the concepts.\",\n",
      "  \"action\": \"wiki\",\n",
      "  \"action_input\": \"Search: \\\"Markov Decision Processes\\\"\",\n",
      "  \"thought\": \"RL is rooted in MDPs (Markov Decision Processes) - a foundational concept.\",\n",
      "  \"action\": \"wiki\",\n",
      "  \"action_input\": \"Search: \\\"Q-Learning\\\"\",\n",
      "  \"thought\": \"The core algorithm – Q-learning – is a starting point.\",\n",
      "  \"action\": \"wiki\",\n",
      "  \"action_input\": \"Search: \\\"Deep Q-Network (DQN)\\\"\",\n",
      "  \"thought\": \"DQN is a popular and relatively approachable method.\",\n",
      "  \"action\": \"wiki\",\n",
      "  \"action_input\": \"Search: \\\"Policy Gradient Methods\\\"\",\n",
      "  \"thought\": \"Policy gradients are often preferred, especially when dealing with complex environments.\",\n",
      "  \"action\": \"wiki\",\n",
      "  \"action_input\": \"Search: \\\"Proximal Policy Optimization (PPO)\\\"\",\n",
      "  \"thought\": \"PPO is a powerful and widely used framework.\",\n",
      "  \"action\": \"wiki\",\n",
      "  \"action_input\": \"Search: \\\"Temporal Difference Learning (TDL)\\\"\",\n",
      "  \"thought\": \"TDL is a classic method used in many RL applications.  We'll touch on it briefly.\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mNo good Wikipedia Search Result was found\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mOkay, let’s start with a foundational roadmap. Given your existing ML/DL background, we'll focus on building a solid understanding of core concepts before diving into algorithms.\n",
      "\n",
      "**Phase 1: Foundations – Understanding the Basics**\n",
      "\n",
      "1. **Markov Decision Processes (MDPs):**  A deep understanding of MDPs is crucial. Learn the components – states, actions, rewards, transition probabilities, and discount factors.  This will provide a conceptual framework for how RL works. Resources: [arxiv](https://arxiv.org/abs/?)\n",
      "2. **Q-Learning:**  This is the cornerstone of many RL algorithms.  Understand the Q-table, Q-values, exploration vs. exploitation, and the Bellman equation. [wiki](https://en.wikipedia.org/wiki/Q-learning)\n",
      "3. **Deep Q-Networks (DQN):**  DQN is a practical application of Q-learning. It introduces the concept of neural networks for function approximation, crucial for handling large state spaces. [arxiv](https://arxiv.org/abs/?)\n",
      "4. **Policy Gradient Methods:**  Understand the core idea of optimizing a policy (a mapping from states to actions) rather than just learning Q-values.  This will focus on algorithms like REINFORCE and Actor-Critic methods. [wiki](https://en.wikipedia.org/wiki/Policy_gradient)\n",
      "\n",
      "\n",
      "**Phase 2:  Exploring Advanced Concepts (After Initial Foundation)**\n",
      "\n",
      "1. **Exploration & Exploitation:**  Learn about balancing exploration (trying new things) and exploitation (using what you already know).  This is a critical challenge in RL. [wiki](https://en.wikipedia.org/wiki/Exploration_vs_exploitation)\n",
      "2. **Value Iteration & Policy Iteration:**  Understand these methods for iterative refinement of the policy.  [wiki](https://en.wikipedia.org/wiki/Value_iteration)\n",
      "3. **Deep Reinforcement Learning (DRL):**  Expand into the use of neural networks for function approximation, which is key for complex environments. [arxiv](https://arxiv.org/abs/?)\n",
      "\n",
      "\n",
      "**Phase 3:  Practical Applications & Considerations**\n",
      "\n",
      "1. **Simulated Environments:**  You'll likely want to train your RL agents in simulated environments. Learn how to design and evaluate those environments. [wiki](https://en.wikipedia.org/wiki/Simulation)\n",
      "2. **Reward Shaping:**  Learn how to design reward functions that guide the agent toward the desired behavior. [wiki](https://en.wikipedia.org/wiki/Reward_shaping)\n",
      "3. **Regularization:**  Understand techniques like dropout and L1/L2 regularization to prevent overfitting. [wiki](https://en.wikipedia.org/wiki/Regularization)\n",
      "\n",
      "**Important Notes for You:**\n",
      "\n",
      "*   **Start Small:** Begin with Q-Learning and DQN - these are relatively straightforward to grasp initially.\n",
      "*   **Visualization:** Focus on understanding the concepts through visualizations.  Think about what the Q-table looks like and how it represents the best action to take in a given state.\n",
      "\n",
      "This roadmap provides a solid foundation. I will continue to refine this based on your progress and feedback. Do you want me to delve deeper into any of these phases, or perhaps start with a specific example (e.g., how Q-learning is used in a game)?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"From Arxiv, give me a roadmap to learn reinforcement learning, keep in mind that i'm already good at machine learning and deep learning, but I don't know much about RL.\",\n",
       " 'output': \"Okay, let’s start with a foundational roadmap. Given your existing ML/DL background, we'll focus on building a solid understanding of core concepts before diving into algorithms.\\n\\n**Phase 1: Foundations – Understanding the Basics**\\n\\n1. **Markov Decision Processes (MDPs):**  A deep understanding of MDPs is crucial. Learn the components – states, actions, rewards, transition probabilities, and discount factors.  This will provide a conceptual framework for how RL works. Resources: [arxiv](https://arxiv.org/abs/?)\\n2. **Q-Learning:**  This is the cornerstone of many RL algorithms.  Understand the Q-table, Q-values, exploration vs. exploitation, and the Bellman equation. [wiki](https://en.wikipedia.org/wiki/Q-learning)\\n3. **Deep Q-Networks (DQN):**  DQN is a practical application of Q-learning. It introduces the concept of neural networks for function approximation, crucial for handling large state spaces. [arxiv](https://arxiv.org/abs/?)\\n4. **Policy Gradient Methods:**  Understand the core idea of optimizing a policy (a mapping from states to actions) rather than just learning Q-values.  This will focus on algorithms like REINFORCE and Actor-Critic methods. [wiki](https://en.wikipedia.org/wiki/Policy_gradient)\\n\\n\\n**Phase 2:  Exploring Advanced Concepts (After Initial Foundation)**\\n\\n1. **Exploration & Exploitation:**  Learn about balancing exploration (trying new things) and exploitation (using what you already know).  This is a critical challenge in RL. [wiki](https://en.wikipedia.org/wiki/Exploration_vs_exploitation)\\n2. **Value Iteration & Policy Iteration:**  Understand these methods for iterative refinement of the policy.  [wiki](https://en.wikipedia.org/wiki/Value_iteration)\\n3. **Deep Reinforcement Learning (DRL):**  Expand into the use of neural networks for function approximation, which is key for complex environments. [arxiv](https://arxiv.org/abs/?)\\n\\n\\n**Phase 3:  Practical Applications & Considerations**\\n\\n1. **Simulated Environments:**  You'll likely want to train your RL agents in simulated environments. Learn how to design and evaluate those environments. [wiki](https://en.wikipedia.org/wiki/Simulation)\\n2. **Reward Shaping:**  Learn how to design reward functions that guide the agent toward the desired behavior. [wiki](https://en.wikipedia.org/wiki/Reward_shaping)\\n3. **Regularization:**  Understand techniques like dropout and L1/L2 regularization to prevent overfitting. [wiki](https://en.wikipedia.org/wiki/Regularization)\\n\\n**Important Notes for You:**\\n\\n*   **Start Small:** Begin with Q-Learning and DQN - these are relatively straightforward to grasp initially.\\n*   **Visualization:** Focus on understanding the concepts through visualizations.  Think about what the Q-table looks like and how it represents the best action to take in a given state.\\n\\nThis roadmap provides a solid foundation. I will continue to refine this based on your progress and feedback. Do you want me to delve deeper into any of these phases, or perhaps start with a specific example (e.g., how Q-learning is used in a game)?\"}"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\"From Arxiv, give me a roadmap to learn reinforcement learning, keep in mind that i'm already good at machine learning and deep learning, but I don't know much about RL.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0b8a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b899d55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
